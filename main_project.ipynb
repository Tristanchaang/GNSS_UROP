{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNSS Timeseries Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium as fol\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as wg\n",
    "from ipywidgets import HBox, VBox\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import math\n",
    "import geopy.distance\n",
    "import json\n",
    "import os\n",
    "from os.path import exists\n",
    "from os import makedirs\n",
    "from datetime import datetime\n",
    "import random\n",
    "import urllib.request\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from earthscope_sdk.auth.device_code_flow import DeviceCodeFlowSimple\n",
    "from earthscope_sdk.auth.auth_flow import NoTokensError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orglist = [\"UNR\", \"JPL\", \"UNAV\"]\n",
    "\n",
    "def make_if_absent(folderpath):\n",
    "    if not exists(folderpath):\n",
    "        makedirs(folderpath)\n",
    "\n",
    "make_if_absent(\"data\")\n",
    "for orgname in orglist:\n",
    "    make_if_absent(\"data/\"+orgname+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_of = {}\n",
    "\n",
    "for org in orglist:\n",
    "    filepath = \"data/\" + org + \"_data.json\"\n",
    "    if exists(filepath):\n",
    "        with open(filepath, \"r\") as data_file:\n",
    "            data_of[org] = json.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Detrend Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitTS(xdata,ydata,sig):\n",
    "    '''Fit times series.  Linear trend currently\n",
    "    data is xdata time in days, ydata (NEU), sig \n",
    "    https://en.wikipedia.org/wiki/Generalized_least_squares\n",
    "    https://en.wikipedia.org/wiki/Reduced_chi-squared_statistic\n",
    "    Outputs:\n",
    "    array([grad, y-int]), [grad, grad_sd], [Wrms, chi_sq, ndata]\n",
    "    '''\n",
    "        \n",
    "    yr = xdata/365.25; # Years Since 2000/1/1\n",
    "    OmInv = 1./sig**2\n",
    "    ndata = int(xdata.size)  # number of data points\n",
    "    X = np.vstack((np.ones(ndata),yr)).T\n",
    "    Bvec = (X.T * OmInv) @ ydata.T\n",
    "    MCov = np.linalg.inv((X.T * OmInv) @ X)\n",
    "    MEst = MCov @ Bvec\n",
    "    Res = ydata - X @ MEst\n",
    "\n",
    "    chi = np.sqrt((Res.T @ (Res*OmInv))/(ndata-2))\n",
    "    wrms = np.sqrt(ndata/np.sum(OmInv))*chi\n",
    "    \n",
    "    return np.flip(MEst), [MEst[1],np.sqrt(MCov[1,1])], [wrms,chi,ndata]\n",
    "\n",
    "def detrended(xdata, ydata, sig):\n",
    "    m, c = FitTS(xdata, ydata, sig)[0]\n",
    "    return ydata - (m * xdata / 365.25 + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FETCH TIMESERIES DATA - UNR \n",
    "\n",
    "SigLim = (10,10,30) # standard deviation\n",
    "\n",
    "# UNR Data Fetcher\n",
    "def Read_UNR(site, Update):\n",
    "    # !! check for if site has no network\n",
    "    site_info = data_of[\"UNR\"][site]\n",
    "\n",
    "    file_directory = \"./data/UNR/\"+site.upper()+\".\"+site_info[\"networks\"][0]+\".csv\"\n",
    "    file_name = site.upper()+\".\"+site_info[\"networks\"][0]+\".tenv3\"\n",
    "    fetch_url=\"http://geodesy.unr.edu/gps_timeseries/tenv3/plates/\"+site_info[\"networks\"][0]+\"/\"+file_name\n",
    "\n",
    "    if exists(file_directory) and not bool(Update) :\n",
    "        print('Reading from file ',file_directory)\n",
    "        df = pd.read_csv(file_directory,delimiter=',')\n",
    "    else:\n",
    "        print('Downloading from ',fetch_url)\n",
    "        df = pd.read_csv(fetch_url,delimiter=r\"\\s+\",header=1)\n",
    "        df.to_csv(file_directory,index=False)\n",
    "\n",
    "    ninit = len(df)\n",
    "    # Remove data with NEU sigmas > 10, 10 and 30 mm.\n",
    "    # Apply sequencially because 'and' does not seem to work\n",
    "    if SigLim[0] > 0:\n",
    "        df=df[df.iloc[:,14]<SigLim[0]/1000]\n",
    "        df=df[df.iloc[:,15]<SigLim[1]/1000]\n",
    "        df=df[df.iloc[:,16]<SigLim[2]/1000]\n",
    "        print(\"Number after >{} {} {} mm NEU sigma removal\".format(*SigLim),len(df),\"Read\",ninit)\n",
    "    npdat = df.to_numpy()\n",
    "\n",
    "    # Extract time \n",
    "    t=list(npdat[:,1])\n",
    "    nd=list((npdat[:,10]-npdat[0,10])*1000) # remove first value so starts at zero\n",
    "    # the same a UNAV. (Problem if times of first data point are different)\n",
    "    ed=list((npdat[:,8]-npdat[0,8])*1000)\n",
    "    ud=list((npdat[:,12]-npdat[0,12])*1000) \n",
    "    ns=list(npdat[:,15]*1000) ; es=list(npdat[:,14]*1000) ; us=list(npdat[:,16]*1000)\n",
    "\n",
    "    n = 0\n",
    "    to = []\n",
    "    td = np.zeros(len(t))\n",
    "    for v in t:\n",
    "        to = np.append(to, datetime.strptime(v, '%y%b%d'))\n",
    "        dt = to[n] - datetime(2000, 1, 1,0,0)  # Time difference from 2000/1/1\n",
    "        td[n] = dt.total_seconds()/86400.  # Days from 2000/1/1\n",
    "        n += 1\n",
    "\n",
    "    tseries = [td, nd, ns, ed, es, ud, us]\n",
    "    times = to\n",
    "    return times, tseries\n",
    "\n",
    "def Read_JPL(site, Update):\n",
    "    # !! check for if site has no network\n",
    "    csv_file_directory = \"./data/JPL/\"+site+\".csv\"\n",
    "    \n",
    "    fetch_url=\"https://sideshow.jpl.nasa.gov/pub/JPL_GPS_Timeseries/repro2018a/post/point/\"+site+\".series\"\n",
    "\n",
    "    if exists(csv_file_directory) and not bool(Update):\n",
    "        print('Reading from file',csv_file_directory)\n",
    "        df = pd.read_csv(csv_file_directory,delimiter=',')\n",
    "    else:\n",
    "        print('Downloading from ',fetch_url)\n",
    "        df = pd.read_csv(fetch_url,delimiter=r\"\\s+\")\n",
    "        df.to_csv(csv_file_directory,index=False)\n",
    "\n",
    "    ninit = len(df)\n",
    "    # Remove data with NEU sigmas > 10, 10 and 30 mm.\n",
    "    # Apply sequencially because 'and' does not seem to work\n",
    "    if SigLim[0] > 0:\n",
    "        df=df[df.iloc[:,5]<SigLim[0]/1000]\n",
    "        df=df[df.iloc[:,4]<SigLim[1]/1000]\n",
    "        df=df[df.iloc[:,6]<SigLim[2]/1000]\n",
    "        print(\"Number after >{} {} {} mm NEU sigma removal\".format(*SigLim),len(df),\"Read\",ninit)\n",
    "\n",
    "    npdat = df.to_numpy()\n",
    "\n",
    "    nd=list((npdat[:,2]-npdat[0,2])*1000) # 3rd column, remove first value so starts at zero\n",
    "    # the same a UNAV. (Problem if times of first data point are different)\n",
    "    ed=list((npdat[:,1]-npdat[0,1])*1000) # 2nd column\n",
    "    ud=list((npdat[:,3]-npdat[0,3])*1000) # 4th column\n",
    "    ns=list(npdat[:,5]*1000) ; es=list(npdat[:,4]*1000) ; us=list(npdat[:,6]*1000) # what do any of these meannnn\n",
    "    to = np.empty(len(npdat[:,10]), dtype = object)\n",
    "\n",
    "    for i in range(len(to)):\n",
    "        each_date = datetime((int(npdat[:,11][i])), int((npdat[:,12][i])), int((npdat[:,13][i])))\n",
    "        to[i] = each_date\n",
    "\n",
    "    td_counter = 0\n",
    "    td = np.zeros(len(npdat[:,10]))\n",
    "    for time_value in npdat[:,10]:\n",
    "        td[td_counter] = time_value/31557600 # days from 2000/1/1\n",
    "        td_counter += 1\n",
    "\n",
    "    tseries = [td, nd, ns, ed, es, ud, us]\n",
    "    times = to\n",
    "    # print(to)\n",
    "    return times, tseries\n",
    "\n",
    "\n",
    "def get_es_file(url, directory_to_save_file='./', token_path='./'):\n",
    "    \"\"\"function to get earthscope data using es-sdk\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        url of desired file at gage-data.earthscope.org\n",
    "    directory_to_save_file : str, optional\n",
    "        path of directory in which to save the file, by default cwd\n",
    "    token_path : str, optional\n",
    "        path of directory in which to save the token, by default './'\n",
    "    \"\"\"\n",
    "    # instantiate the device code flow subclass\n",
    "    device_flow = DeviceCodeFlowSimple(Path(token_path))\n",
    "    try:\n",
    "      # get access token from local path\n",
    "      device_flow.get_access_token_refresh_if_necessary()\n",
    "    except NoTokensError:\n",
    "      # if no token was found locally, do the device code flow\n",
    "      device_flow.do_flow()\n",
    "    token = device_flow.access_token\n",
    "\n",
    "    # request a file and provide the token in the Authorization header\n",
    "    file_name = Path(url).name\n",
    "\n",
    "    r = requests.get(url, headers={\"authorization\": f\"Bearer {token}\"})\n",
    "    if r.status_code == requests.codes.ok:\n",
    "      # save the file\n",
    "      with open(Path(Path(directory_to_save_file) / file_name), 'wb') as f:\n",
    "        for data in r:\n",
    "            f.write(data)\n",
    "    else:\n",
    "      #problem occured\n",
    "      print(f\"failure: {r.status_code}, {r.reason}\")\n",
    "\n",
    "\n",
    "def Read_UNAV(site, Update):\n",
    "    '''Function to read data from UNAVCO and return numpy array and datetime arrays.\n",
    "    Input:\n",
    "       sites - 4-character site name\n",
    "       Update - 1 Re-read data from server; 0 Use existing copy\n",
    "    Output\n",
    "       times   - date-times dates thar can be used in plotting\n",
    "       tseries - time series with days for 2000/1/1, dn,sn, de,se, du, su'''\n",
    "    global SigLim\n",
    "    # Incase of token refresh problems may need\n",
    "    #!es sso refresh\n",
    "\n",
    "    # Create the file name and URL\n",
    "    filen = site.upper()+\".cwu.nam14.csv\"\n",
    "    whurl=\"https://data.unavco.org/archive/gnss/products/position/\"+site.upper()+\"/\"+filen\n",
    "\n",
    "    #PBO Station Position Time Series.\n",
    "    #Format Version, 1.2.0\n",
    "    #Reference Frame, NAM14\n",
    "    #4-character ID, P177\n",
    "    #Station name, CoDeTierraCN2008\n",
    "    #Begin Date, 2008-05-09\n",
    "    #End Date, 2021-10-06\n",
    "    #Release Date, 2021-10-07\n",
    "    #Source file, P177.cwu.nam14.pos\n",
    "    #Offset from source file, 166.01 mm North, -139.45 mm East, -3.62 mm Vertical\n",
    "    #Reference position, 37.5281683684 North Latitude, -122.4950535711 East Longitude, 71.79172 meters elevation\n",
    "    #Date, North (mm), East (mm), Vertical (mm), North Std. Deviation (mm), East Std. Deviation (mm), Vertical Std. Deviation (mm), Quality,\n",
    "    #2008-05-09,0.00, 0.00, 0.00, 2.08, 1.66, 7.84, repro,\n",
    "    #2008-05-10,0.38, 0.83, 2.66, 2.13, 1.7, 7.99, repro,\n",
    "    #...\n",
    "    # print(filen, whurl)\n",
    "    if exists(filen) and not bool(Update):\n",
    "        print('Reading from file',filen)\n",
    "        df = pd.read_csv(filen,delimiter=',',header=11)\n",
    "    else:\n",
    "        print('Downloading from ',whurl)\n",
    "        get_es_file(whurl)\n",
    "        df = pd.read_csv(filen,delimiter=',',header=11)\n",
    "        # Write csv local copy for later use\n",
    "        #print('Creating',filen)\n",
    "        #df.to_cvs(filen)\n",
    "        # df.to_csv(filen,index=False)\n",
    "\n",
    "    ninit = len(df)\n",
    "    # Remove data with NEU sigmas > 10, 10 and 30 mm.\n",
    "    # Apply sequencially because 'and' does not seem to work (latter use values\n",
    "    # extracted from GUI box)\n",
    "    if SigLim[0] > 0 :\n",
    "        df=df[df.iloc[:,4]<SigLim[0]];\n",
    "        df=df[df.iloc[:,5]<SigLim[1]];\n",
    "        df=df[df.iloc[:,6]<SigLim[2]];\n",
    "        print(\"Number after >{} {} {} mm NEU sigma removal\".format(*SigLim),len(df),\"Read\",ninit)\n",
    "\n",
    "    npdat =df.to_numpy()\n",
    "    # Extract time,and data and sigma\n",
    "    t=list(npdat[:,0]);nd=list(npdat[:,1]); ed=list(npdat[:,2]); ud=list(npdat[:,3]);\n",
    "    ns=list(npdat[:,4]) ; es=list(npdat[:,5]) ; us=list(npdat[:,6])\n",
    "    # Now convert the time into a datetime type (to) and days from 2000/01/01\n",
    "    # as float array (td).\n",
    "    # We can use 'to' in plotting and 'td' for fitting to data\n",
    "    n = 0\n",
    "    to = []\n",
    "    td = np.zeros(len(t))\n",
    "    for v in t:\n",
    "        to = np.append(to,datetime.strptime(v, '%Y-%m-%d'))\n",
    "        dt = to[n] - datetime(2000, 1, 1)  # Time difference from 2000/1/1\n",
    "        td[n] = dt.total_seconds()/86400.  # Days from 2000/1/1\n",
    "        n += 1\n",
    "\n",
    "    # Now construct data array\n",
    "    tseries = np.array([td,nd,ns,ed,es,ud,us])\n",
    "    times = to\n",
    "    return times, tseries\n",
    "\n",
    "\n",
    "Read = {\n",
    "        \"UNR\": Read_UNR,\n",
    "        \"JPL\": Read_JPL,\n",
    "        \"UNAV\": Read_UNAV\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERAL MAP OPERATIONS\n",
    "\n",
    "d_km = lambda coords1, coords2: geopy.distance.geodesic(coords1,coords2).km\n",
    "d_mi = lambda coords1, coords2: geopy.distance.geodesic(coords1,coords2).miles\n",
    "\n",
    "def plot_locations(map, coordslist, tooltiplist, color=\"blue\", dotrad = 2):\n",
    "    \"\"\"\n",
    "    map: Folium map\n",
    "    coordslist: [(lat1, lon1), (lat2,lon2), ...]\n",
    "    tooltip: [tag1, tag2, ...]\n",
    "    \"\"\"\n",
    "    for coords,tooltip in zip(coordslist,tooltiplist):\n",
    "        fol.CircleMarker(\n",
    "                location=coords,\n",
    "                tooltip=tooltip,\n",
    "                radius = dotrad,\n",
    "                stroke = False,\n",
    "                fill_color = color,\n",
    "                fill_opacity = 1,\n",
    "                opacity = 1,\n",
    "                #icon=fol.Icon(icon=\"globe\"),\n",
    "            ).add_to(map)\n",
    "\n",
    "\n",
    "def nearby_sites(site_data, site, radius_in_km):\n",
    "    \"\"\"\n",
    "    site = ID of a site OR coordinates provided as a list\n",
    "    radius_in_km = radius within which we want to plot sites\n",
    "    Returns: [ (neighbor_property, lat, lon, distance from site), ... ]\n",
    "    \"\"\"\n",
    "    if site[0] in \"([\": # if it's a coordinate pair instead of a site id\n",
    "        site = list(eval(site))\n",
    "        \n",
    "    cur_coords = site\n",
    "\n",
    "    if isinstance(site,str):\n",
    "        cur_coords = site_data[site][\"location\"]\n",
    "\n",
    "    assert not isinstance(cur_coords[0],str) # by now cur_coords is a coordinate pair regardless of input\n",
    "\n",
    "    answer = []\n",
    "\n",
    "    for siteid in site_data:\n",
    "        try:\n",
    "            site_coords = site_data[siteid][\"location\"]\n",
    "            distance = d_km(site_coords, cur_coords)\n",
    "            if distance < radius_in_km and site != siteid:\n",
    "                answer.append((siteid,*site_coords,distance))\n",
    "        except: pass\n",
    "\n",
    "    return answer, cur_coords # offset specifies whether we include nearest site or not (depends on if we input a site or coordinate pair)\n",
    "\n",
    "\n",
    "def basic_circle(map, center, radius_in_km):\n",
    "    fol.Circle(\n",
    "        location=center,\n",
    "        radius=radius_in_km * 1000, # in metres\n",
    "        color=\"black\",\n",
    "        weight=1,\n",
    "        fill_opacity=0.0,\n",
    "        opacity=1,\n",
    "        fill_color=\"green\",\n",
    "        fill=True,  # gets overridden by fill_color\n",
    "        #tooltip=\"I am in meters\",\n",
    "    ).add_to(map)\n",
    "\n",
    "def vec_add(c1,c2):\n",
    "    return [c1[0]+c2[0], c1[1]+c2[1]]\n",
    "\n",
    "def draw_vector(map, center, direction, scale, color=\"black\"):\n",
    "    dvec = [direction[0] * scale * abs(math.cos(center[0] * math.pi/180 )), direction[1] * scale]\n",
    "    endpoint = vec_add(center, dvec)\n",
    "    fol.PolyLine(locations=[center, endpoint],weight=2,color = color).add_to(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brac(string):\n",
    "    '''\n",
    "    \"P123 (UNR)\" --> (\"P123\", \"UNR\")\n",
    "    '''\n",
    "    i=-1\n",
    "    while string[i] != '(': i-=1\n",
    "    return string[:i-1], string[i+1:-1]\n",
    "\n",
    "\n",
    "def plot_ts_graph(siteid, org, Update, detrend, ax0, ax1, ax2, yearrange, errorbars):\n",
    "    '''\n",
    "    Adding a single plot to the original plot defined in plot_ts_graph_list()\n",
    "    '''\n",
    "    \n",
    "    times, tseries = Read[org](siteid, Update)\n",
    "    td, nd, ns, ed, es, ud, us = tseries\n",
    "\n",
    "    ## restricting timeseries to yearrange\n",
    "    # find the start and end index\n",
    "    start, end = 0, len(td)\n",
    "    while times[start] < yearrange[0]: start+=1\n",
    "    while times[end-1] > yearrange[1]: end-=1\n",
    "    # restrict\n",
    "    times, td = times[start:end], td[start:end]\n",
    "    nd, ns = nd[start:end], ns[start:end]\n",
    "    ed, es = ed[start:end], es[start:end]\n",
    "    ud, us = ud[start:end], us[start:end]\n",
    "\n",
    "    if detrend: \n",
    "        nd = detrended(np.array(td), np.array(nd), np.array(ns))\n",
    "        ed = detrended(np.array(td), np.array(ed), np.array(es))\n",
    "        ud = detrended(np.array(td), np.array(ud), np.array(us))\n",
    "    \n",
    "    if errorbars:\n",
    "        # ax0.errorbar(times,nd,yerr=[ns,ns],errorevery=1, ecolor='black')\n",
    "        # ax1.errorbar(times,ed,yerr=[es,es],errorevery=1, ecolor='black')\n",
    "        # ax2.errorbar(times,ud,yerr=[us,us],errorevery=1, ecolor='black')\n",
    "        ax0.fill(list(times) + list(reversed(times)), \n",
    "                 list(np.array(nd)+np.array(ns)) + list(np.flip(np.array(nd)-np.array(ns))), \n",
    "                 alpha=0.4, linewidth=3, label=\"_\"+siteid)\n",
    "        ax1.fill(list(times) + list(reversed(times)), \n",
    "                 list(np.array(ed)+np.array(es)) + list(np.flip(np.array(ed)-np.array(es))), \n",
    "                 alpha=0.4, linewidth=3, label=\"_\"+siteid)\n",
    "        ax2.fill(list(times) + list(reversed(times)), \n",
    "                 list(np.array(ud)+np.array(us)) + list(np.flip(np.array(ud)-np.array(us))), \n",
    "                 alpha=0.4, linewidth=3, label=\"_\"+siteid)\n",
    "    \n",
    "    ax0.plot(times,nd, linewidth=0.5, label=siteid + \" (\" + org + \")\")\n",
    "    ax1.plot(times,ed, linewidth=0.5, label=siteid + \" (\" + org + \")\")\n",
    "    ax2.plot(times,ud, linewidth=0.5, label=siteid + \" (\" + org + \")\")\n",
    "\n",
    "\n",
    "def plot_ts_graph_list(idlist, Update, yearrange, detrend = False, errorbars = False, resolution = \"Low Res\"):\n",
    "    '''\n",
    "    Plots the timeseries of a list of sites.\n",
    "    '''\n",
    "    plt.figure(figsize=(15, 10), dpi = {\"HD\": 600, \"Regular\": 300, \"Low Res\": 100}[resolution])\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[1, 1, 1]) \n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax0.set_ylabel(\"ΔNorth\")\n",
    "    ax0.yaxis.set_tick_params(labelrotation=90)\n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "    \n",
    "    ax1 = plt.subplot(gs[1], sharex = ax0)\n",
    "    ax1.set_ylabel(\"ΔEast\")\n",
    "    ax1.yaxis.set_tick_params(labelrotation=90)\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax2 = plt.subplot(gs[2], sharex = ax0)\n",
    "    ax2.set_ylabel(\"ΔUp\")\n",
    "    ax2.yaxis.set_tick_params(labelrotation=90)\n",
    "    ax2.set_xlabel(\"Time\")\n",
    "\n",
    "    for idorg in idlist:\n",
    "        plot_ts_graph(*remove_brac(idorg), Update, detrend, ax0, ax1, ax2, yearrange, errorbars)\n",
    "\n",
    "    ax0.legend(bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    plt.subplots_adjust(hspace=.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetcher Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buttons\n",
    "update_UNR_butt     = wg.Button(description=\"Latest UNR\", icon = \"download\")\n",
    "update_JPL_butt     = wg.Button(description=\"Latest JPL\", icon = \"download\")\n",
    "update_UNAV_butt    = wg.Button(description=\"Latest UNAV\", icon = \"download\")\n",
    "# Outputs\n",
    "fetcher_output      = wg.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Availability Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "site_searchbar      = wg.Text(value=None,placeholder='Site ID',description='Check Availability:',disabled=False, style= {'description_width': 'initial'})\n",
    "org_avail_select    = wg.Dropdown(options=orglist+['other'], value='UNR', disabled=False, layout=wg.Layout(width='100px'))\n",
    "site_search_submit  = wg.Button(description=\"Search!\", icon = \"search\")\n",
    "clear_log_butt      = wg.Button(description=\"Clear Log\", icon = \"times\")\n",
    "# Style\n",
    "site_search_submit.style.button_color = 'rgb(196,253,196)'\n",
    "clear_log_butt.style.button_color = 'mistyrose'\n",
    "# Outputs\n",
    "availability_output = wg.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "map = [\"Not initialized yet!\"] # allow direct editing of the map via entry mutation\n",
    "layout              = lambda w: wg.Layout(width=w, height='40px')\n",
    "new_map_butt        = wg.Button(description=\"Clear / New Map\", icon = \"map\")\n",
    "reload_map_butt     = wg.Button(description=\"Reload Map\", icon = \"refresh\")\n",
    "close_map_butt      = wg.Button(description=\"Close Map\", icon = \"times\")\n",
    "site_center         = wg.Text(value=None,placeholder='Site ID',description='Site:',disabled=False, style= {'description_width': 'initial'}, layout=layout(\"150px\"))\n",
    "org_map_select      = wg.Dropdown(options=orglist+['other'], value='UNR', disabled=False, layout=wg.Layout(width='100px'))\n",
    "site_radius         = wg.Text(value=None,placeholder='in km',description='Radius:',disabled=False, style= {'description_width': 'initial'}, layout=layout(\"150px\"))\n",
    "site_circle_submit  = wg.Button(description=\"Add Plot!\", icon = \"map-marker\")\n",
    "plot_graph_butt     = wg.Button(description=\"Plot Distances\", icon = \"line-chart\")\n",
    "enter_code_form     = wg.Text(value=None, placeholder='Not Implemented Yet')\n",
    "plot_vec_check      = wg.Checkbox(description=\"Plot Velocities\", value=False)\n",
    "# Style\n",
    "new_map_butt.style.button_color = 'rgb(196,253,196)'\n",
    "reload_map_butt.style.button_color = 'oldlace'\n",
    "close_map_butt.style.button_color = 'mistyrose'\n",
    "site_circle_submit.style.button_color = 'paleturquoise'\n",
    "plot_graph_butt.style.button_color = 'paleturquoise'\n",
    "# Outputs\n",
    "map_output          = wg.Output()\n",
    "nearest_site_output = wg.Output()\n",
    "graph_output        = wg.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "ts_site_form        = wg.Text(value=None,placeholder='Site ID',disabled=False, style= {'description_width': 'initial'}, layout=layout(\"150px\"))\n",
    "org_ts_select       = wg.Dropdown(options=orglist+['other'], value='UNR', disabled=False, layout=wg.Layout(width='100px'))\n",
    "append_butt         = wg.Button(description=\"Add to List\", icon = \"plus-square\")\n",
    "plot_ts_butt        = wg.Button(description=\"Plot\", icon = \"line-chart\")\n",
    "plot_ts_res         = wg.Dropdown(options=['HD', 'Regular', 'Low Res'], value='Low Res', disabled=False, layout=wg.Layout(width='100px'))\n",
    "close_ts_butt       = wg.Button(description=\"Close Graph\", icon = \"times\")\n",
    "clear_list_butt     = wg.Button(description=\"Clear List\", icon = \"times\")\n",
    "ts_sites            = wg.SelectMultiple(options=[], value=[], description='Site List:')\n",
    "error_bar_check     = wg.Checkbox(description=\"Error Bars\", value=False)\n",
    "detrend_check       = wg.Checkbox(description=\"Detrend\", value=False)\n",
    "live_update_check   = wg.Checkbox(description=\"Live Update\", value=False)\n",
    "start_year_form     = wg.Text(value=None,placeholder='YYYY-MM-DD',description='Start:',disabled=False, style= {'description_width': 'initial'}, layout=layout(\"150px\"))\n",
    "end_year_form       = wg.Text(value=None,placeholder='YYYY-MM-DD',description='End:',disabled=False, style= {'description_width': 'initial'}, layout=layout(\"150px\"))\n",
    "siglim_form         = wg.Text(value=None,placeholder='(10,10,30)',description='SigLim:',disabled=False, style= {'description_width': 'initial'}, layout=layout(\"150px\"))\n",
    "# Style\n",
    "append_butt.style.button_color = 'rgb(196,253,196)'\n",
    "plot_ts_butt.style.button_color = 'paleturquoise'\n",
    "close_ts_butt.style.button_color = 'mistyrose'\n",
    "clear_list_butt.style.button_color = 'mistyrose'\n",
    "# Outputs\n",
    "timeseries_output   = wg.Output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UpdateUNR(_):\n",
    "    with fetcher_output:\n",
    "        print(\"Downloading Data from UNR...\")\n",
    "\n",
    "    plates_site = \"http://geodesy.unr.edu/gps_timeseries/sta_frames.txt\"\n",
    "    coords_site = \"http://geodesy.unr.edu/NGLStationPages/llh.out\"\n",
    "    \n",
    "    plates_list = str(urllib.request.urlopen(plates_site).read())[2:].split(\" \\\\n\")[:-1]\n",
    "    coords_list = str(urllib.request.urlopen(coords_site).read())[2:].split(\" \\\\n\")[:-1]\n",
    "    \n",
    "    for_json = {}\n",
    "\n",
    "    for siteplate in plates_list:\n",
    "        siteplates = [el for el in siteplate.split(\" \") if el]\n",
    "        for_json.setdefault(siteplates[0], {'location': None, 'networks': []})\n",
    "        for_json[siteplates[0]]['networks'] = siteplates[1:]\n",
    "    \n",
    "    for sitecoord in coords_list:\n",
    "        siteid, lon, lat, height = (el for el in sitecoord.split(\" \") if el)\n",
    "        for_json.setdefault(siteid, {'location': None, 'networks': []})\n",
    "        for_json[siteid]['location'] = [float(lon), float(lat)]\n",
    "    \n",
    "    global data_of\n",
    "    data_of[\"UNR\"] = for_json\n",
    "\n",
    "    with open('./data/UNR_data.json', 'w') as f:\n",
    "        json.dump(for_json, f)\n",
    "        \n",
    "    with fetcher_output:\n",
    "        print(\"Latest UNR Data Downloaded\")\n",
    "\n",
    "update_UNR_butt.on_click(UpdateUNR)\n",
    "\n",
    "\n",
    "def UpdateJPL(_):\n",
    "    with fetcher_output:\n",
    "        print(\"Downloading Data from JPL...\")\n",
    "\n",
    "    coords_site = \"https://sideshow.jpl.nasa.gov/post/tables/table2.html\"\n",
    "    x = str(urllib.request.urlopen(coords_site).read()).split(\"\\\\n\")\n",
    "    sitecoordlist = [[xxx for xxx in xx.split(\" \") if xxx]\n",
    "                     for xx in x if \"POS\" in xx]\n",
    "    sitevellist = [[xxx for xxx in xx.split(\" \") if xxx]\n",
    "                     for xx in x if \"VEL\" in xx]\n",
    "    # [['AB01', 'POS', '52.2095', '-174.2048', '25492.217', '0.034', '0.024', '0.098'], ...]\n",
    "    for_json = {}\n",
    "    for element in sitecoordlist:\n",
    "        for_json[element[0]] = {'location': [float(element[2]),float(element[3])]}\n",
    "    for element in sitevellist:\n",
    "        for_json[element[0]]['velocity'] = [float(element[2]),float(element[3])]\n",
    "    \n",
    "    global data_of\n",
    "    data_of[\"JPL\"] = for_json\n",
    "\n",
    "    with open('./data/JPL_data.json', 'w') as f:\n",
    "        json.dump(for_json, f)\n",
    "    \n",
    "    with fetcher_output:\n",
    "        print(\"Latest JPL Data Downloaded\")\n",
    "update_JPL_butt.on_click(UpdateJPL)\n",
    "\n",
    "\n",
    "def UpdateUNAV(_):\n",
    "    with fetcher_output:\n",
    "        print(\"Downloading Data from UNAV...\")\n",
    "\n",
    "    coords_site = \"https://www.unavco.org/instrumentation/networks/status/data/geoJSON/network-monitoring\"\n",
    "    \n",
    "    x = json.loads(urllib.request.urlopen(coords_site).read())\n",
    "\n",
    "    # [['AB01', 'POS', '52.2095', '-174.2048', '25492.217', '0.034', '0.024', '0.098'], ...]\n",
    "    for_json = {}\n",
    "    for element in x['features']:\n",
    "        for_json[element[\"id\"]] = {\n",
    "            'location': [element['geometry']['coordinates'][1],element['geometry']['coordinates'][0]], \n",
    "            'region': element['properties']['region']}\n",
    "    \n",
    "    global data_of\n",
    "    data_of[\"UNAV\"] = for_json\n",
    "\n",
    "    with open('./data/UNAV_data.json', 'w') as f:\n",
    "        json.dump(for_json, f)\n",
    "    \n",
    "    with fetcher_output:\n",
    "        print(\"Latest UNAV Data Downloaded\")\n",
    "update_UNAV_butt.on_click(UpdateUNAV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def site_search(b):\n",
    "    searched = site_searchbar.value.upper() \n",
    "    with availability_output:\n",
    "        try:\n",
    "            print(searched + \"(\" + org_avail_select.value + \")\", \": \", data_of[org_avail_select.value][searched])\n",
    "        except:\n",
    "            display(wg.HTML('''<em style=\"color:red\">Not Found!</em>'''))\n",
    "site_search_submit.on_click(site_search)\n",
    "\n",
    "\n",
    "def clear_avail_log(b):\n",
    "    availability_output.clear_output()\n",
    "clear_log_butt.on_click(clear_avail_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_map(b):\n",
    "    map_output.clear_output()\n",
    "    map[0] = fol.Map(control_scale=True,\n",
    "                   location=(40, -100),\n",
    "                   zoom_start=4,\n",
    "                   width = 1100,\n",
    "                   height = 600)\n",
    "    with map_output:\n",
    "        display(map[0])\n",
    "new_map_butt.on_click(new_map)\n",
    "\n",
    "def reload_map(b):\n",
    "    map_output.clear_output()\n",
    "    with map_output:\n",
    "        display(map[0])\n",
    "reload_map_butt.on_click(reload_map)\n",
    "\n",
    "def close_map(b):\n",
    "    map_output.clear_output()\n",
    "    nearest_site_output.clear_output()\n",
    "    graph_output.clear_output()\n",
    "    map[0] = \"Not initialized yet!\"\n",
    "close_map_butt.on_click(close_map)\n",
    "\n",
    "################\n",
    "# SITE BUTTONS #\n",
    "################\n",
    "\n",
    "def site_circle(b):\n",
    "    siteid, rad = site_center.value, float(site_radius.value) if site_radius.value else None\n",
    "    plotvec = plot_vec_check.value\n",
    "    \n",
    "    if rad:\n",
    "        site_list, center = nearby_sites(data_of[org_map_select.value], siteid, rad)\n",
    "        basic_circle(map[0], center, rad)\n",
    "        plot_locations(map[0], [el[1:3] for el in site_list], [el[0] for el in site_list])\n",
    "        \n",
    "        if plotvec:\n",
    "            for el in site_list:\n",
    "                plot_velocity(el[0], org_map_select.value)\n",
    "    \n",
    "    if siteid[0] in \"[(\":\n",
    "        siteid = list(eval(siteid))\n",
    "    \n",
    "    plot_locations(map[0], \n",
    "                   [data_of[org_map_select.value][siteid][\"location\"] if isinstance(siteid, str) else siteid], \n",
    "                   [siteid], color=\"black\", dotrad = 4)\n",
    "    \n",
    "    if plotvec:\n",
    "        plot_velocity(siteid, org_map_select.value)\n",
    "\n",
    "    reload_map(b)\n",
    "site_circle_submit.on_click(site_circle)\n",
    "\n",
    "\n",
    "def nn_graph(b):\n",
    "    siteid, rad = site_center.value, float(site_radius.value) if site_radius.value else None\n",
    "\n",
    "    if not rad:\n",
    "        nearest_site_output.clear_output()\n",
    "        graph_output.clear_output()\n",
    "        return\n",
    "\n",
    "    site_list, _ = nearby_sites(data_of[org_map_select.value], siteid, rad)\n",
    "    neighbours = sorted(site_list, key = lambda x: x[3])[:10]\n",
    "    \n",
    "    nearest_site_output.clear_output()\n",
    "    with nearest_site_output:\n",
    "        display(wg.HTML(\"\"\"<h2>10 Nearest Neighbouring Sites:</h2>\"\"\"))\n",
    "        tableHTML = f\"<table><tr><th><b>Site</b></th><th><b>Distance from {siteid}</b></th></tr>\"\n",
    "        for s,_,_,d in neighbours: tableHTML += f\"<tr><td>{s}</td><td>{d:.3f} km</td></tr>\"\n",
    "        display(wg.HTML(tableHTML + \"</table>\"))\n",
    "        \n",
    "    graph_output.clear_output()\n",
    "    with graph_output:\n",
    "        display(wg.HTML(\"\"\"<h2 style=\"text-align:center;\">Distances to Nearby Sites (km)</h2>\"\"\"))\n",
    "        X = range(len(neighbours))\n",
    "        plt.bar([x[0] for x in neighbours], [x[3] for x in neighbours])\n",
    "        plt.show()\n",
    "plot_graph_butt.on_click(nn_graph)\n",
    "\n",
    "\n",
    "def get_vel(siteid, org):\n",
    "    try:\n",
    "        return data_of[org][siteid][\"velocity\"]\n",
    "    except:\n",
    "        times, tseries = Read[org](siteid, 0)\n",
    "        td, nd, ns, ed, es, ud, us = tseries\n",
    "        return [FitTS(np.array(td), np.array(nd), np.array(ns))[1][0], \n",
    "                FitTS(np.array(td), np.array(ed), np.array(es))[1][0]]\n",
    "\n",
    "\n",
    "def plot_velocity(siteid, org):\n",
    "    xdot,ydot = get_vel(siteid, org)\n",
    "    data_of[org][siteid][\"velocity\"] = [xdot, ydot]\n",
    "    draw_vector(map[0], data_of[org][siteid][\"location\"], [xdot, ydot], 0.2, color=\"black\")\n",
    "# enter_code_butt.on_click(plot_velocity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ts_list(x):\n",
    "    siteid = ts_site_form.value\n",
    "    \n",
    "    # check validity\n",
    "    if siteid not in data_of[org_ts_select.value]:\n",
    "        timeseries_output.clear_output()\n",
    "        with timeseries_output:\n",
    "            display(wg.HTML('''<em style=\"color:red\">Invalid site! Try again.</em>'''))\n",
    "    else:\n",
    "        extendedsiteid = siteid + \" (\" + org_ts_select.value + \")\"\n",
    "        if extendedsiteid not in ts_sites.options:\n",
    "            ts_sites.options = list(ts_sites.options) + [extendedsiteid]\n",
    "        \n",
    "    ts_site_form.value = \"\"\n",
    "    \n",
    "append_butt.on_click(update_ts_list)\n",
    "\n",
    "def list_to_graph(x):\n",
    "    selected = list(ts_sites.value)\n",
    "    timeseries_output.clear_output()\n",
    "\n",
    "    if siglim_form.value:\n",
    "        global SigLim\n",
    "        try: \n",
    "            nlim, elim, ulim = eval(siglim_form.value)\n",
    "            assert all(isinstance(lim,int) for lim in [nlim, elim, ulim])\n",
    "        except:\n",
    "            nlim, elim, ulim = 10, 10, 30\n",
    "        SigLim = (nlim, elim, ulim)\n",
    "    \n",
    "    # check validity\n",
    "    \n",
    "    yearrange = [datetime(1,1,1), datetime(3000,1,1)] # [far past, far future]\n",
    "\n",
    "    if selected:\n",
    "        if start_year_form.value: yearrange[0] = datetime.strptime(start_year_form.value, \"%Y-%m-%d\")\n",
    "        if end_year_form.value: yearrange[1] = datetime.strptime(end_year_form.value, \"%Y-%m-%d\")\n",
    "\n",
    "        with timeseries_output:\n",
    "            plot_ts_graph_list(\n",
    "                selected, \n",
    "                int(live_update_check.value), \n",
    "                yearrange, \n",
    "                detrend = detrend_check.value, \n",
    "                errorbars = error_bar_check.value,\n",
    "                resolution = plot_ts_res.value\n",
    "                )\n",
    "    else:\n",
    "        with timeseries_output:\n",
    "            display(wg.HTML('''<em style=\"color:red\">Select a set of sites!</em>'''))\n",
    "\n",
    "    ts_site_form.value = \"\"\n",
    "\n",
    "plot_ts_butt.on_click(list_to_graph)\n",
    "\n",
    "def close_ts(b):\n",
    "    timeseries_output.clear_output()\n",
    "close_ts_butt.on_click(close_ts)\n",
    "\n",
    "def clear_list(b):\n",
    "    ts_sites.options = []\n",
    "clear_list_butt.on_click(clear_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_window = VBox([\n",
    "    wg.HTML(\n",
    "            '<em style=\"color:blue; line-height: 1.5\">Use the buttons below to update the local files with the latest data. This may take a few seconds.</em>'\n",
    "            ),\n",
    "    HBox([update_UNR_butt, update_JPL_butt, update_UNAV_butt]),\n",
    "    fetcher_output\n",
    "])\n",
    "\n",
    "availability_window = VBox([\n",
    "    wg.HTML('<h1>Availability</h1>'),\n",
    "    wg.HTML(\n",
    "            '<em style=\"color:blue; line-height: 1.5\"><ul>' + \n",
    "            '<li>Type the Site ID into the box below to check its existence and status.</li>' +\n",
    "            '</ul></em>'\n",
    "            ),\n",
    "    HBox([site_searchbar, org_avail_select, site_search_submit, clear_log_butt]),\n",
    "    availability_output\n",
    "    ])\n",
    "\n",
    "map_window = VBox([\n",
    "    wg.HTML('<h1>Map</h1>'),\n",
    "    wg.HTML(\n",
    "        '<em style=\"color:blue; line-height: 1.5\"><ul>' + \n",
    "        '<li>Click New Map to initialize a new map that you can plot on. You can click on this button any time to reset a new map.</li>' +\n",
    "        '<li>Type the Site ID and the radius within which you want to detect other sites. Click Add Plot to overlay the circle.</li>' +\n",
    "        '<li>Click Plot Distances to show the top 10 nearest sites.</li>' +\n",
    "        '</ul></em>'\n",
    "    ),\n",
    "    HBox([new_map_butt, reload_map_butt, close_map_butt, enter_code_form, plot_vec_check]),\n",
    "    HBox([site_center, org_map_select, site_radius, site_circle_submit, plot_graph_butt]),\n",
    "    HBox([nearest_site_output, graph_output]),\n",
    "    map_output\n",
    "    ])\n",
    "\n",
    "timeseries_window = VBox([\n",
    "    wg.HTML('<h1>Timeseries</h1>'),\n",
    "    wg.HTML(\n",
    "        '<em style=\"color:blue; line-height: 1.5\"><ul>' + \n",
    "        '<li>Input a Site ID to add it to the list.</li>' +\n",
    "        '<li>Select multiple sites from the list by holding cmd/ctrl to plot multiple sites. Click Plot to plot the timeseries.</li>' +\n",
    "        '<li>Plotting parameters:<ul>' + \n",
    "        '<li>Check Error Bars to show error bars. </li>' +\n",
    "        '<li>Check Detrend to plot a linearly detrended timeseries. </li>' + \n",
    "        '<li>Check Live Update to download the latest timeseries of all the sites chosen before plotting.<br>(Without Live Update, the latest timeseries is downloaded only if it is not available locally.) </li>' + \n",
    "        '<li>Adjust SigLim = (nlim, elim, ulim) to remove NEU with sigmas > nlim, elim, ulim. By default, SigLim = (10,10,30).</li>' + \n",
    "        '<li>Use Start/End Year to restrict the time series to that year range.</li>'\n",
    "        '</ul></li>' +\n",
    "        '</ul></em>'\n",
    "    ),\n",
    "    HBox([ts_site_form, org_ts_select, append_butt]),\n",
    "    HBox([start_year_form, end_year_form, siglim_form, error_bar_check, detrend_check, live_update_check]),\n",
    "    HBox([ts_sites,VBox\n",
    "          ([HBox([clear_list_butt, close_ts_butt]),\n",
    "            HBox([plot_ts_butt, plot_ts_res])])\n",
    "        ]),\n",
    "    timeseries_output\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface\n",
    "\n",
    "To open the interface in the browser using the Voila package, comment the first line and then uncomment the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(fetch_window, availability_window, map_window, timeseries_window)\n",
    "\n",
    "import nbformat as nbf\n",
    "\n",
    "newcell = nbf.notebooknode.NotebookNode(\n",
    "    cell_type='code',\n",
    "    execution_count = 0,\n",
    "    metadata = {},\n",
    "    outputs= [],\n",
    "    source='display(fetch_window, availability_window, map_window, timeseries_window)')\n",
    "\n",
    "ntbk = nbf.read(\"main_project.ipynb\", nbf.NO_CONVERT)\n",
    "ntbk.cells = [cell for cell in ntbk.cells if cell.cell_type != \"markdown\"][:-1] + [newcell]\n",
    "\n",
    "nbf.write(ntbk, \"temp.ipynb\", version=nbf.NO_CONVERT)\n",
    "\n",
    "! voila temp.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
